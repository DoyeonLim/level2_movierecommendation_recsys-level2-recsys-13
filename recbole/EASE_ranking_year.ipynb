{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fce7f7d-61cc-4e9a-b3ef-d955d21271f5",
   "metadata": {},
   "source": [
    "### 2 stages(Candidates -> Ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674dc6eb-ee0f-4fa5-ad75-c8f75234fb7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Candidates: EASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5277683-2d36-4d11-92a1-9a82f293073b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from recbole.model.context_aware_recommender.fm import FM\n",
    "from recbole.quick_start import run_recbole\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import *\n",
    "\n",
    "# to be manually modified\n",
    "context = False\n",
    "MODEL = 'EASE'\n",
    "version = 'v2'\n",
    "data_path = f'/opt/ml/input/data/tr_v2_miss_year'\n",
    "\n",
    "base = f'{version}_base'\n",
    "atomic_path = f'/opt/ml/input/data/{version}_base/{version}_base'\n",
    "yaml_path = f'/opt/ml/input/data/{version}_base/{version}_base.yaml'\n",
    "inter_df = pd.read_csv(os.path.join(\n",
    "    data_path, 'interactions.csv'))  # 전체 학습 데이터\n",
    "genre_df = pd.read_csv(join(data_path, 'genres.csv'))\n",
    "title_df = pd.read_csv(join(data_path, 'titles.csv'))\n",
    "director_df = pd.read_csv(join(data_path, 'directors.csv'))\n",
    "writer_df = pd.read_csv(join(data_path, 'writers.csv'))\n",
    "year_df = pd.read_csv(join(data_path, 'years.csv'))\n",
    "\n",
    "# yaml\n",
    "# to be manually modified\n",
    "cfg_str = \"\"\"\n",
    "data_path: /opt/ml/input/data/\n",
    "dataset: v2_base\n",
    "\n",
    "field_separator: \"\\\\t\"\n",
    "seq_separator: \"\\\\t\"\n",
    "\n",
    "USER_ID_FIELD: user\n",
    "ITEM_ID_FIELD: item\n",
    "TIME_FIELD: time\n",
    "#YEAR_FIELD: year\n",
    "#TITLE_FIELD: title\n",
    "#seq_len: { genre: 10, writer: 10, director: 10 }\n",
    "\n",
    "load_col:\n",
    "  inter: [user, item, time]\n",
    "  # item: [item, year, title, genre, writer, director]\n",
    "  # item: [item, genre, year, writer, director]\n",
    "\n",
    "# model config\n",
    "reg_weight: 500\n",
    "embedding_size: 10 # (int) The embedding size of features.\n",
    "mlp_hidden_size: [16, 16, 16] # (list of int) The hidden size of MLP layers.\n",
    "dropout_prob: 0.2 # (float) The dropout rate.\n",
    "\n",
    "# Training and evaluation config\n",
    "eval_setting: RO_RS,full\n",
    "epochs: 10\n",
    "seed: 42\n",
    "train_batch_size: 2048 #4096\n",
    "eval_batch_size: 2048 #4096\n",
    "eval_args:\n",
    "  split: { \"RS\": [0.9, 0.05, 0.05] }\n",
    "  order: RO\n",
    "  group_by: \"user\"\n",
    "  mode: full\n",
    "topk: 10\n",
    "train_neg_sample_args:\n",
    "  distribution: uniform\n",
    "  sample_num: 1\n",
    "  alpha: 1.0\n",
    "  dynamic: False\n",
    "  candidate_num: 0\n",
    "metrics: [\"Recall\", \"MRR\", \"NDCG\", \"Hit\", \"Precision\"]\n",
    "valid_metric: Recall@10\n",
    "\n",
    "# logging\n",
    "show_progress: false\n",
    "\"\"\"\n",
    "yaml = yaml_path\n",
    "with open(yaml, \"w\") as f:\n",
    "    f.write(cfg_str)\n",
    "\n",
    "# dataset\n",
    "inter_cols = {'user': 'user:token', 'item': 'item:token', 'time': 'time:float'}\n",
    "atom_inter = convert_to_atomic(inter_df, inter_cols)\n",
    "save_atomic(atom_inter, atomic_path, 'inter')\n",
    "\n",
    "# run\n",
    "run_recbole(\n",
    "    model=MODEL,\n",
    "    dataset=base,\n",
    "    config_file_list=[yaml],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a031c-bcd5-4d61-98a5-ab5d8f897a91",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d15f60-1526-4d6d-af67-d01cf924e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "base = '/opt/ml/'\n",
    "# path = base + 'input/recbole/submission_EASE.csv'\n",
    "path = base + 'input/recbole/EASE_100.csv'\n",
    "\n",
    "top100 = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d2d72-4584-4614-b8cc-f46b2ac00806",
   "metadata": {},
   "source": [
    "#### Ranking: top 10을 고르되 유저 별 min_year <= item <= max_year 내에 존재하지 않으면 다음 candidate으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655388c2-a76b-4453-a1cf-cd49cbda21bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user, item dataframe에서 user_consumptions_movie_min_max_year를 유저 별로 계산\n",
    "years_df  = pd.read_csv(base+'input/data/tr_v2_miss_year/years.csv')\n",
    "genres_df  = pd.read_csv(base+'input/data/tr_v2_miss_year/genres.csv')\n",
    "\n",
    "inters_df = pd.read_csv(base+'input/data/tr_v2_miss_year/interactions.csv')\n",
    "inters_df.drop(columns='time', inplace=True)\n",
    "\n",
    "iy_df = inters_df.merge(years_df, on='item')\n",
    "iy_df = iy_df.sort_values(by=['user', 'item'])\n",
    "\n",
    "user_consumptions_movie_min_max_year = iy_df.groupby('user')['year'].agg(['min', 'max'])\n",
    "user_consumptions_movie_min_max_year = user_consumptions_movie_min_max_year.to_dict()\n",
    "\n",
    "# item2year dict\n",
    "item_year_df = years_df.groupby('item')['year'].first()\n",
    "item_year_dict = item_year_df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307aafb-46ed-4972-8dec-fb8f0c621aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# takes 7 mins\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Callable\n",
    "\n",
    "def Rank(top100: pd.DataFrame, condition: Callable):\n",
    "    \"\"\"\n",
    "    1. top100 df에서 유저 별로\n",
    "    2. 아이템이 user_consumptions_movie_min_max_year 내에 포함되면 top10에 포함\n",
    "    3. 포함되지 않으면 넘어감\n",
    "    \"\"\" \n",
    "    from collections import defaultdict\n",
    "    \n",
    "    top10_dict = defaultdict(list)\n",
    "    skipped    = defaultdict(int)\n",
    "    fanatic    = defaultdict(int)\n",
    "    already    = {k: 9 for k in top100.user.unique()}\n",
    "    for index, row in tqdm(top100.iterrows()):\n",
    "        user, item = row['user'], row['item']\n",
    "        year = item_year_dict[item]\n",
    "        genres = item2genres[item]\n",
    "        \n",
    "        if len(top10_dict[user]) == 10:\n",
    "            continue\n",
    "            \n",
    "        if condition(user, year, genres):\n",
    "            top10_dict[user].append(item)\n",
    "        else:\n",
    "            skipped[user] += 1\n",
    "\n",
    "    return top10_dict, skipped\n",
    "\n",
    "def condition(user, year, genres):\n",
    "    return user_consumptions_movie_min_max_year['min'][user] + down \\\n",
    "        <= year <= (user_consumptions_movie_min_max_year['max'][user] + up)\n",
    "        \n",
    "top_items, skipped = Rank(top100, condition) # both dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec0b05a-2c9b-4295-b1b5-efae3410e7c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "import pandas as pd\n",
    "\n",
    "df_normalized = pivoted_df.div(pivoted_df.sum(axis=1), axis=0)\n",
    "\n",
    "# 2.\n",
    "from tqdm.notebook import tqdm\n",
    "top = 0\n",
    "app = []\n",
    "pec = []\n",
    "for index, row in tqdm(df_normalized.iterrows()):\n",
    "    a = row.nlargest(1)\n",
    "    r = a.item()\n",
    "    pec.append((index, r, a.index.item()))\n",
    "        \n",
    "# 3.\n",
    "item2genres = {item: set(group['genre']) for item, group in df.groupby('item')}\n",
    "print(item2genres[1])\n",
    "\n",
    "# 4.\n",
    "pec = {user: genre for user, _, genre in pec}\n",
    "print(pec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aae554-f0a0-4f95-8c65-c8c7fca6b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_skips(skipped):\n",
    "    s = sum(v for k, v in skipped.items())\n",
    "    return s, s/31360\n",
    "\n",
    "get_num_skips(skipped)\n",
    "\n",
    "# exp 1: max_year+3 -> (787, 0.02509566326530612)\n",
    "# exp 2: min-2 <= item <= max_year+2 -> (409, 0.013042091836734694)\n",
    "# exp 3: genre 30% >= -> include, or just top 10 from the top -> (5251, 0.16744260204081632)\n",
    "# exp 4: min-2 <= item <= max_year+2 -> (409, 0.013042091836734694)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50873327-758a-44c4-87d2-5cf15645f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert len(top100.user.unique().tolist()) == len(list(top_items.keys())) # 31360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488542d0-383e-42f3-83c4-109f5e4aff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "top10s = defaultdict(list)\n",
    "topK = 10\n",
    "for i, (user, tops) in tqdm(enumerate(top_items.items())):\n",
    "    top10s[user] = tops[:topK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153a4a8-1520-418c-9de0-cc19aac10dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "a = []\n",
    "for k, v in top10s.items():\n",
    "    if len(v) != 10:\n",
    "        a.append(k)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc9114-1c79-444f-8cec-fb59579bbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "total_item_set = set(df['item'])\n",
    "users = df['user'].unique()\n",
    "\n",
    "def recommend_items(df):\n",
    "    recommendations = {}\n",
    "    for user in tqdm(a):\n",
    "        items = df[df['user'] == user]['item']\n",
    "        recommendations[user] = random.sample((total_item_set.union(set(top10s[a[user]]))) - set(items), 1)\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed3fc42-2a89-4554-9e92-42c4964d22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = {}\n",
    "for user in tqdm(a):\n",
    "    items = df[df['user'] == user]['item']\n",
    "    s = set(items).union(set(top10s[user]))\n",
    "    recommendations[user] = random.sample(total_item_set - s, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16699c71-b5f7-42c4-b423-1d3d1213dc2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make submission df out of top10s (dict)\n",
    "pd.DataFrame({'user': top10s.keys(), 'item': top10s.values()})\\\n",
    "    .explode('item')\\\n",
    "    .to_csv('EASE_year_up_down_2_check.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
